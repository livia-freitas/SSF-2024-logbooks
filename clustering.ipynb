{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d2d10a-c2bb-4241-85ea-97780bd9b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster\n",
    "import scipy.stats\n",
    "import scipy.spatial.distance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58329e3f-4436-46eb-b937-484b15c2ba39",
   "metadata": {},
   "source": [
    "# Load word embeddings (FastText model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a55114-014f-485f-99d9-38551e17805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify path for embeddings file\n",
    "\n",
    "# # these embeddings come with the gensim package\n",
    "# cap_path = datapath(\"crime-and-punishment.bin\")\n",
    "cap_path = datapath(\"lee_fasttext.bin\")\n",
    "\n",
    "# # The following embeddings were downloaded from:\n",
    "# # https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "# # and saved to \"data\" directory.\n",
    "# cap_path = \"data/wiki/wiki.en.bin\" \n",
    "\n",
    "## load the embeddings\n",
    "fbkv = load_facebook_vectors(cap_path)\n",
    "wind_terms = []\n",
    "n_rows = 13\n",
    "for i in np.arange(0,n_rows):\n",
    "    rows_before = max(i, 0)\n",
    "    rows_after = n_rows-(i+1)\n",
    "    wind_terms.append(\n",
    "        pd.read_csv(\"wind_terms_no_commas.txt\", sep=\", \",skiprows=rows_before, skipfooter = rows_after, header=None, engine=\"python\")\n",
    "    )\n",
    "\n",
    "#categories = [\"calm\", \"light air\", \"light breeze\", \"gentle breeze\", \"moderate breeze\", \"fresh breeze\",\n",
    "    #\"strong breeze\", \"near gale\", \"gale\", \"strong gale\", \"storm\", \"violent storm\", \"hurricane\"]\n",
    "\n",
    "fbkv_list = []\n",
    "for term in wind_terms:\n",
    "    fbkv_list.append(fbkv[term])\n",
    "\n",
    "# remove all the previous existing rows, make it one big vector\n",
    "fbkv_vector = []\n",
    "for i in range(0,13):\n",
    "    row_length = len(fbkv_list[i])\n",
    "    for j  in range(0, row_length):\n",
    "        fbkv_vector.append(fbkv_list[i][j])\n",
    "    #wind_array = np.asarray(fbkv_list, dtype=\"object\")\n",
    "\n",
    "#df = pd.DataFrame(wind_array) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792ccdf-f0b8-4dbf-9aa1-70cbe19f182b",
   "metadata": {},
   "source": [
    "#### Look at a few embedding examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a213f31f-55d9-47a5-9ef2-de88f646d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation coefficients\n",
      "0.8776445185363406\n",
      "0.9384719648907758\n",
      "\n",
      "cosine distances\n",
      "0.11786442995071411\n",
      "0.06028550863265991\n"
     ]
    }
   ],
   "source": [
    "print(\"correlation coefficients\")\n",
    "print(scipy.stats.pearsonr(fbkv[\"strong gust\"], fbkv[\"heavy gale\"])[0])\n",
    "print(scipy.stats.pearsonr(fbkv[\"light breeze\"], fbkv[\"heavy gale\"])[0])\n",
    "print()\n",
    "print(\"cosine distances\")\n",
    "print(scipy.spatial.distance.cosine(fbkv[\"strong gust\"], fbkv[\"heavy gale\"]))\n",
    "print(scipy.spatial.distance.cosine(fbkv[\"light breeze\"], fbkv[\"heavy gale\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ed847-56b2-4f24-a4cc-eeee335078ea",
   "metadata": {},
   "source": [
    "# Make training data by embedding the logbook data\n",
    "(below, we're just using random embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe29adb9-9ee8-4c3e-885d-e26e49df0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fbkv_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80813a-fda4-4da0-9c34-fd99e599355e",
   "metadata": {},
   "source": [
    "# Train clustering model on embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1975666-4b83-41d5-8434-c5a1b23504c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 8, ..., 3, 2, 5], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize (untrained model)\n",
    "kmeans_model = sklearn.cluster.KMeans(n_clusters=9, n_init=\"auto\")\n",
    "\n",
    "## fit the model to training data\n",
    "kmeans_model.fit(X_train)\n",
    "\n",
    "## cluster the training data\n",
    "beaufort_predictions = kmeans_model.predict(X_train)\n",
    "\n",
    "beaufort_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff13a74-a28f-425e-92f3-1cc54259d920",
   "metadata": {},
   "source": [
    "# Plot the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc013c6-0188-4de7-89f5-fcabc2a4fbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
