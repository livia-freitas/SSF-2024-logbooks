{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d2d10a-c2bb-4241-85ea-97780bd9b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.cluster import KMeans \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58329e3f-4436-46eb-b937-484b15c2ba39",
   "metadata": {},
   "source": [
    "# Load word embeddings (FastText model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a55114-014f-485f-99d9-38551e17805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify path for embeddings file\n",
    "\n",
    "# # these embeddings come with the gensim package\n",
    "# cap_path = datapath(\"crime-and-punishment.bin\")\n",
    "cap_path = datapath(\"lee_fasttext.bin\")\n",
    "\n",
    "# # The following embeddings were downloaded from:\n",
    "# # https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "# # and saved to \"data\" directory.\n",
    "# cap_path = \"data/wiki/wiki.en.bin\" \n",
    "\n",
    "## load the embeddings\n",
    "fbkv = load_facebook_vectors(cap_path)\n",
    "wind_terms = []\n",
    "n_rows = 13\n",
    "for i in np.arange(0,n_rows):\n",
    "    rows_before = max(i, 0)\n",
    "    rows_after = n_rows-(i+1)\n",
    "    wind_terms.append(\n",
    "        pd.read_csv(\"wind_terms_no_commas.txt\", sep=\", \",skiprows=rows_before, skipfooter = rows_after, header=None, engine=\"python\")\n",
    "    )\n",
    "\n",
    "#categories = [\"calm\", \"light air\", \"light breeze\", \"gentle breeze\", \"moderate breeze\", \"fresh breeze\",\n",
    "    #\"strong breeze\", \"near gale\", \"gale\", \"strong gale\", \"storm\", \"violent storm\", \"hurricane\"]\n",
    "\n",
    "fbkv_list = []\n",
    "for term in wind_terms:\n",
    "    fbkv_list.append(fbkv[term])\n",
    "\n",
    "fbkv_vector = []\n",
    "indices = []\n",
    "for i in range(n_rows):\n",
    "    row_length = len(fbkv_list[i])\n",
    "    indices.append(row_length)\n",
    "    for j  in range(row_length):\n",
    "        fbkv_vector.append(fbkv_list[i][j])\n",
    "    #wind_array = np.asarray(fbkv_list, dtype=\"object\")\n",
    "\n",
    "wind_terms\n",
    "\n",
    "# IMPERFECT SOLUTION TO THE WEIRD 3 DIMENSIONALITY OF WIND TERMS\n",
    "\n",
    "#vector without the last category\n",
    "wind_vector = []\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(indices[i]):\n",
    "        #print(\"loop iteration: \" + str(i) + \" column: \" + str(j))\n",
    "        wind_vector.append(wind_terms[i][j][0])\n",
    "\n",
    "#number 10 is giving us trouble\n",
    "#df = pd.DataFrame(wind_array) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ed847-56b2-4f24-a4cc-eeee335078ea",
   "metadata": {},
   "source": [
    "# Make training data by embedding the logbook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe29adb9-9ee8-4c3e-885d-e26e49df0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fbkv_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80813a-fda4-4da0-9c34-fd99e599355e",
   "metadata": {},
   "source": [
    "# Train clustering model on embedded data (no seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1975666-4b83-41d5-8434-c5a1b23504c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  0, ..., 10,  2,  9], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beaufort_terms = [fbkv[\"calm\"], fbkv[\"light air\"], fbkv[\"light breeze\"], fbkv[\"gentle breeze\"], fbkv[\"moderate breeze\"], fbkv[\"fresh breeze\"], fbkv[\"strong breeze\"], fbkv[\"near gale\"], fbkv[\"gale\"], fbkv[\"strong gale\"], fbkv[\"storm\"], fbkv[\"violent storm\"], fbkv[\"hurricane\"]]\n",
    "\n",
    "kmeans_model = sklearn.cluster.KMeans(n_clusters=13, init=beaufort_terms, n_init=\"auto\")\n",
    "\n",
    "## fit the model to training data\n",
    "kmeans_model.fit(X_train)\n",
    "## cluster the training data\n",
    "beaufort_predictions = kmeans_model.predict(X_train)\n",
    "\n",
    "beaufort_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff13a74-a28f-425e-92f3-1cc54259d920",
   "metadata": {},
   "source": [
    "# Print the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc013c6-0188-4de7-89f5-fcabc2a4fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter rows of original data\n",
    "d = {'term': wind_vector, 'cluster': beaufort_predictions}\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "\n",
    "columns = {}\n",
    "for i in range(n_rows):\n",
    "    columns.update({i : df[beaufort_predictions == i]})\n",
    "    \n",
    "df = df.sort_values(by = 'cluster', axis = 0)\n",
    "\n",
    "df.to_csv(\"new.txt\", sep=' ', columns = ['term'], index = False, mode='a') # prints all wind terms\n",
    "\n",
    "\n",
    "cluster_list = []\n",
    "\n",
    "def is_str(variable):\n",
    "    if isinstance(variable, str):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "for i in range(n_rows):\n",
    "    df_u = df[df['cluster'] == i]\n",
    "    term_list = df_u['term'].tolist()\n",
    "    cluster_list.append(filter(is_str, term_list))\n",
    "\n",
    "\n",
    "\n",
    "string_list = []\n",
    "for i in range(n_rows):\n",
    "    string_list.append(', '.join(cluster_list[i]))\n",
    "\n",
    "file = open('seeded_clusters.txt','w')\n",
    "file.write(\"\\nK-means clusters (Beaufort terms used as seeds)\\n\")\n",
    "for i in range(n_rows):\n",
    "\tfile.write(\"\\nCluster \" + str(i) + \"\\n\" + string_list[i] + \"\\n\")\n",
    "file.close()\n",
    "#df[beaufort_predictions == 0].to_csv('cluster0.txt', header=True, index=None, sep=' ', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
